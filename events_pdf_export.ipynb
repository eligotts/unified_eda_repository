{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import snowflake.connector\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.subplots as sp\n",
    "import plotly.io as pio\n",
    "import os\n",
    "from datetime import date, datetime, timedelta\n",
    "import gdown\n",
    "\n",
    "## PDF INFO\n",
    "\n",
    "pdf_folder_name = 'events_pdfs'\n",
    "folder_path = os.path.join(os.getcwd(),pdf_folder_name)\n",
    "if not os.path.exists(folder_path):\n",
    "    os.mkdir(folder_path)\n",
    "\n",
    "## COLUMN CONSTANTS\n",
    "\n",
    "# EVENT TABLE COLS - fill with \"\" if not applicable\n",
    "EVENT_DATE_COL = 'event_date'\n",
    "CUST_ID_COL = 'customer_id'\n",
    "EVENT_TYPE_COL = 'event_type'\n",
    "EVENT_DESC_COL = 'event_description'\n",
    "EVENT_ID_COL = 'event_id'\n",
    "\n",
    "# CUSTOMER INFO TABLE - fill with \"\" if not applicable\n",
    "AGE_COL = 'age'\n",
    "GENDER_COL = 'gender'\n",
    "START_D_COL = 'start_date'\n",
    "LOCATION_COL = 'location'\n",
    "SALARY_COL = 'salary'\n",
    "\n",
    "splitting_cols_numeric = [AGE_COL,SALARY_COL,START_D_COL]\n",
    "splitting_cols_cat = [AGE_COL,GENDER_COL,LOCATION_COL]\n",
    "time_intervals = ['month','week','day_of_week'] \n",
    "\n",
    "# Pull data, want 1,000,000 random rows\n",
    "limit_num = 1000000\n",
    "\n",
    "file_id = \"1NsuIREETvfjoFzg3943MOB5Vr2Yc3hHR\"\n",
    "output_file = \"full_events_data.pkl\"\n",
    "\n",
    "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "gdown.download(url, output_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Snowflake (old method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "## SNOWFLAKE INFO\n",
    "account = 'or10868.uae-north.azure'\n",
    "username = 'insait'\n",
    "password = 'Insait123'\n",
    "database = 'FAKEDB'\n",
    "schema = 'EDA116'\n",
    "warehouse = 'COMPUTE_WH'\n",
    "role ='ACCOUNTADMIN'\n",
    "\n",
    "table = 'event_logs_full_with_dep'\n",
    "customer_info = 'customer_info'\n",
    "\n",
    "\n",
    "\n",
    "# Snowflake connection\n",
    "conn = snowflake.connector.connect(\n",
    "    user=username,\n",
    "    password=password,\n",
    "    account=account,\n",
    "    warehouse=warehouse,\n",
    "    database=database,\n",
    "    schema=schema\n",
    ")\n",
    "\n",
    "# Create a cursor object\n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "\n",
    "# Get event log tables, put them into one data frame\n",
    "cursor.execute(f\"SELECT * FROM {schema}.{table} order by RANDOM(42) LIMIT \"+str(limit_num))\n",
    "\n",
    "data = cursor.fetchall()\n",
    "\n",
    "# CLIENT TO DO: order the columns list properly to fit table structure\n",
    "df = pd.DataFrame(data=data, columns = [CUST_ID_COL, EVENT_TYPE_COL, EVENT_ID_COL, EVENT_DATE_COL, \n",
    "                                        EVENT_DESC_COL])\n",
    "df.sort_values(by=EVENT_DATE_COL, inplace=True)\n",
    "\n",
    "# create more accessible date columns given the datetime object\n",
    "df['year'] = df[EVENT_DATE_COL].dt.year\n",
    "df['quarter'] = df[EVENT_DATE_COL].dt.quarter\n",
    "\n",
    "df['month'] = df[EVENT_DATE_COL].dt.month\n",
    "df['week'] = df[EVENT_DATE_COL].dt.isocalendar().week.astype(int)\n",
    "df['day'] = df[EVENT_DATE_COL].dt.day\n",
    "df['hour'] = df[EVENT_DATE_COL].dt.hour\n",
    "df['day_of_week'] = df[EVENT_DATE_COL].dt.dayofweek \n",
    "\n",
    "# Option to pickle the dataframe for efficient access\n",
    "# df.to_pickle(\"./dfpdf.pkl\")\n",
    "\n",
    "# Customer info\n",
    "cursor.execute(f\"SELECT * FROM {schema}.{customer_info}\")\n",
    "data = cursor.fetchall()\n",
    "\n",
    "# CLIENT TO DO: order the columns list properly to fit table structure - add more as needed\n",
    "df_cust_info = pd.DataFrame(data=data, columns = [CUST_ID_COL, AGE_COL, GENDER_COL, START_D_COL, LOCATION_COL, SALARY_COL])\n",
    "\n",
    "# Option to pickle the dataframe for efficient access\n",
    "# df_cust_info.to_pickle('./dfcustpdf.pkl')\n",
    "\n",
    "\n",
    "# Read the pickles, if applicable\n",
    "# df = pd.read_pickle('./dfpdf.pkl')\n",
    "# df_cust_info = pd.read_pickle('./dfcustpdf.pkl')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull data, want 1,000,000 random rows\n",
    "limit_num = 1000000\n",
    "\n",
    "df = pd.read_pickle('./' + output_file)\n",
    "\n",
    "if EVENT_DESC_COL == '':\n",
    "    df[EVENT_DESC_COL] = pd.Series(df[EVENT_TYPE_COL])\n",
    "\n",
    "df_event = df[df['row_category'] == 'event']\n",
    "df_event[EVENT_DATE_COL] = pd.to_datetime(df_event[EVENT_DATE_COL])\n",
    "df_cust_info = df[df['row_category'] == 'cust_info']\n",
    "\n",
    "# create more accessible date columns given the datetime object\n",
    "df_event['year'] = df_event[EVENT_DATE_COL].dt.year\n",
    "df_event['quarter'] = df_event[EVENT_DATE_COL].dt.quarter\n",
    "\n",
    "df_event['month'] = df_event[EVENT_DATE_COL].dt.month\n",
    "df_event['week'] = df_event[EVENT_DATE_COL].dt.isocalendar().week.astype(int)\n",
    "df_event['day'] = df_event[EVENT_DATE_COL].dt.day\n",
    "df_event['hour'] = df_event[EVENT_DATE_COL].dt.hour\n",
    "df_event['day_of_week'] = df_event[EVENT_DATE_COL].dt.dayofweek \n",
    "\n",
    "df_randomized = df_event.sample(frac=1, random_state=42)  # Set random_state for reproducibility\n",
    "\n",
    "# Take the first 1000 rows\n",
    "df = df_randomized.head(limit_num)\n",
    "\n",
    "df.sort_values(by=EVENT_DATE_COL, inplace=True)\n",
    "\n",
    "# CLIENT TO DO: order the columns list properly to fit table structure - add more as needed\\\n",
    "splitting_cols_numeric = [AGE_COL,SALARY_COL,START_D_COL]\n",
    "splitting_cols_cat = [AGE_COL,GENDER_COL,LOCATION_COL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = list(df[CUST_ID_COL].unique())\n",
    "events = list(df[EVENT_TYPE_COL].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLOTS\n",
    "\n",
    "# Barplot\n",
    "plot_name = 'event_frequency'\n",
    "plot_path = os.path.join(folder_path,plot_name)\n",
    "\n",
    "# Check if the folder already exists before creating it\n",
    "if not os.path.exists(plot_path):\n",
    "    os.mkdir(plot_path)\n",
    "    \n",
    "for event in ['All events'] + events:\n",
    "\n",
    "    event_path = os.path.join(plot_path, event)\n",
    "\n",
    "    # Check if the folder already exists before creating it\n",
    "    if not os.path.exists(event_path):\n",
    "        os.mkdir(event_path)\n",
    "\n",
    "    for time_interval in time_intervals:\n",
    "        for dist in [None] + splitting_cols_cat:\n",
    "\n",
    "            dfc = df.copy()\n",
    "            \n",
    "            # For the given time interval, retreive the unique choices and assign them as the x axis values\n",
    "            if time_interval == 'day_of_week':\n",
    "                x_data = [i for i in dfc[time_interval].unique()]\n",
    "            \n",
    "            else:\n",
    "                start_date = dfc[EVENT_DATE_COL].min()\n",
    "                \n",
    "                if time_interval == 'quarter':\n",
    "                    dfc[time_interval] = dfc[EVENT_DATE_COL].apply(lambda x: (x.year - start_date.year) * 4 + (((x.month - 1) // 3 + 1) - ((start_date.month - 1) // 3 + 1)))\n",
    "                \n",
    "                elif time_interval == 'month':\n",
    "                    dfc[time_interval] = dfc[EVENT_DATE_COL].apply(lambda x: (x.year - start_date.year) * 12 + (x.month - start_date.month))\n",
    "                \n",
    "                elif time_interval == 'week':\n",
    "                    dfc[time_interval] = dfc[EVENT_DATE_COL].apply(lambda x: (x - start_date).days // 7)\n",
    "                \n",
    "                elif time_interval == 'day':\n",
    "                    dfc[time_interval] = dfc[EVENT_DATE_COL].apply(lambda x: (x - start_date).days)\n",
    "                \n",
    "                \n",
    "                x_data = [i for i in dfc[time_interval].unique()]\n",
    "            \n",
    "            x_data.sort()\n",
    "            \n",
    "            if dist: #show gender distribution\n",
    "                dfcust = df_cust_info.copy()\n",
    "                \n",
    "                if dist == AGE_COL:\n",
    "                    \n",
    "                # Create an additional column of age ranges\n",
    "                    bin_size = 10\n",
    "                    min_range = (dfcust[AGE_COL].astype(int).min() // bin_size) * bin_size if dfcust[AGE_COL].astype(int).min() % bin_size != 0 else ((dfcust[AGE_COL].astype(int).min() // bin_size) - 1) * bin_size \n",
    "                    max_range = ((dfcust[AGE_COL].astype(int).max() // bin_size) + 1) * bin_size if dfcust[AGE_COL].astype(int).max() % bin_size != 0 else dfcust[AGE_COL].astype(int).max()\n",
    "                    age_ranges = list(range(min_range, max_range + 1, bin_size))\n",
    "\n",
    "                    dfcust['age_group'] = pd.cut(dfcust[AGE_COL].astype(int), bins=age_ranges)\n",
    "                    dfcust['age_group'] = dfcust['age_group'].astype(str)\n",
    "\n",
    "                    # Extract start values using string manipulation\n",
    "                    dfcust['age_group'] = dfcust['age_group'].str.extract(r'\\((.*),').astype(int)\n",
    "                    \n",
    "                    dist = 'age_group'\n",
    "                \n",
    "                \n",
    "                    \n",
    "                dfc = pd.merge(dfc, dfcust[[CUST_ID_COL, dist]], left_on=CUST_ID_COL, right_on=CUST_ID_COL, how='left')\n",
    "                \n",
    "                \n",
    "                # Filter the data according to the choice\n",
    "                if event == 'All events':\n",
    "                    y_data = dfc.groupby(by=[dist])[time_interval].value_counts().sort_index()\n",
    "                else:\n",
    "                    y_data = dfc[dfc[EVENT_TYPE_COL] == event].groupby(by=[dist])[time_interval].value_counts().sort_index()\n",
    "\n",
    "                \n",
    "                trace = []\n",
    "\n",
    "                for g in sorted(list(dfcust[dist].unique())):\n",
    "                    if dist == 'age_group':\n",
    "                        name = str(g) + \" - \" + str(g + bin_size)\n",
    "                    else:\n",
    "                        name = g\n",
    "                    trace.append(go.Bar(x=x_data, y=y_data.loc[g], name=name))\n",
    "\n",
    "\n",
    "            else:\n",
    "                # Filter the data according to the choice\n",
    "                if event == 'All events':\n",
    "                    y_data = dfc[time_interval].value_counts().sort_index()\n",
    "                else:\n",
    "                    y_data = dfc[dfc[EVENT_TYPE_COL] == event][time_interval].value_counts().sort_index()\n",
    "\n",
    "\n",
    "\n",
    "            # Create the bar plot\n",
    "            \n",
    "                trace = [go.Bar(x=x_data, y=y_data)]\n",
    "\n",
    "            # Create the layout\n",
    "            layout = go.Layout(title=f'Events by Time Interval, Event: {event}', xaxis=dict(title=str(time_interval)), yaxis=dict(title=\"Event Count\"), barmode=\"group\")\n",
    "\n",
    "            # Create the figure\n",
    "            fig = go.Figure(data=trace, layout=layout)\n",
    "\n",
    "            if dist:\n",
    "                file_name = f'{event}_{time_interval}_by_{dist}.pdf'\n",
    "            else:\n",
    "                file_name = f'{event}_{time_interval}.pdf'\n",
    "\n",
    "            pio.write_image(fig, os.path.join(event_path,file_name), format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap\n",
    "plot_name = 'heatmap'\n",
    "plot_path = os.path.join(folder_path,plot_name)\n",
    "\n",
    "# Check if the folder already exists before creating it\n",
    "if not os.path.exists(plot_path):\n",
    "    os.mkdir(plot_path)\n",
    "\n",
    "for i in range(len(events)):\n",
    "    event_x = events[i]\n",
    "    for j in range(i, len(events)):\n",
    "        event_y = events[j]\n",
    "        dfc = df.copy()\n",
    "        dfc = dfc[[CUST_ID_COL,EVENT_TYPE_COL,EVENT_DESC_COL,EVENT_DATE_COL]]\n",
    "        # Filter the data according to the two event types chosen\n",
    "        dfc = dfc[(dfc[EVENT_TYPE_COL] == event_x) | (dfc[EVENT_TYPE_COL] == event_y)]\n",
    "        \n",
    "        \n",
    "\n",
    "        # Pivot the DataFrame to get a binary matrix where rows are clients, columns are events,\n",
    "        # and values indicate whether a client performed the event or not.\n",
    "        pivot_df = dfc[[CUST_ID_COL,EVENT_DESC_COL]].pivot_table(index=CUST_ID_COL, columns=EVENT_DESC_COL, aggfunc='size', fill_value=0)\n",
    "\n",
    "        # Calculate the correlation between different events (i.e., how often they occur together).\n",
    "        correlation_matrix = pivot_df.corr()\n",
    "\n",
    "        # Correlation is meaningless when considering the same event on both axes, so fill with NaN value\n",
    "        if event_x == event_y:\n",
    "            np.fill_diagonal(correlation_matrix.values, np.nan)\n",
    "\n",
    "        else:\n",
    "            x_vals = list(dfc[dfc[EVENT_TYPE_COL] == event_x][EVENT_DESC_COL].unique())\n",
    "            y_vals = list(dfc[dfc[EVENT_TYPE_COL] == event_y][EVENT_DESC_COL].unique())\n",
    "            correlation_matrix = correlation_matrix[x_vals]\n",
    "            correlation_matrix = correlation_matrix.filter(items = y_vals, axis=0)\n",
    "\n",
    "        # Create the heatmap trace\n",
    "        trace = go.Heatmap(\n",
    "        z=correlation_matrix.values,\n",
    "        x=correlation_matrix.columns,\n",
    "        y=correlation_matrix.index,\n",
    "        colorscale='Viridis',)\n",
    "\n",
    "        # Create the layout\n",
    "        layout = go.Layout(title='Event Co-occurrence Heatmap', xaxis=dict(title=event_x, tickfont = dict(size = 10)), yaxis=dict(title=event_y,tickfont = dict(size = 5)))\n",
    "\n",
    "        # Create the figure\n",
    "        fig = go.Figure(data=[trace], layout=layout)\n",
    "\n",
    "        file_name = f'{event_x}_{event_y}.pdf'\n",
    "\n",
    "        pio.write_image(fig, os.path.join(plot_path,file_name), format='pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Events by customer\n",
    "plot_name = 'events_by_customer'\n",
    "plot_path = os.path.join(folder_path,plot_name)\n",
    "\n",
    "# Check if the folder already exists before creating it\n",
    "if not os.path.exists(plot_path):\n",
    "    os.mkdir(plot_path)\n",
    "    \n",
    "    \n",
    "for event_type in ['All events'] + events:\n",
    "    \n",
    "    event_path = os.path.join(plot_path,event_type)\n",
    "\n",
    "    # Check if the folder already exists before creating it\n",
    "    if not os.path.exists(event_path):\n",
    "        os.mkdir(event_path)\n",
    "    \n",
    "    for cust in customers[:10]: ## UP TO THE USER TO CHOOSE HOW MANY CUSTOMERS TO SEE\n",
    "        \n",
    "        dfc = df.copy()\n",
    "        dfcopy = dfc\n",
    "\n",
    "        # Create query string to retrieve customer info for all selected customers\n",
    "        query_string = CUST_ID_COL + ' == \"' + cust + '\"'\n",
    "\n",
    "\n",
    "        dfc = dfc.query(query_string)\n",
    "        \n",
    "\n",
    "        # Filter the data according to the user's choice of event \n",
    "        if event_type != \"All events\": \n",
    "\n",
    "\n",
    "            dfc = dfc[dfc[EVENT_TYPE_COL] == event_type]\n",
    "\n",
    "        start = dfcopy[EVENT_DATE_COL].min()\n",
    "        end = dfcopy[EVENT_DATE_COL].max()\n",
    "        span = (end.year - start.year) * 12 + (end.month - start.month) + (float((end.day - start.day)/30))\n",
    "\n",
    "\n",
    "        x_data = list(dfc[EVENT_DESC_COL].unique())\n",
    "\n",
    "\n",
    "\n",
    "        # Create the bar plot\n",
    "        trace = []\n",
    "        custs = [cust]\n",
    "        for cust in custs:\n",
    "\n",
    "            # For each customer, retrieve the counts of the given events. Must reindex by the x axis for value alignment\n",
    "            y_data = list(dfc[dfc[CUST_ID_COL] == cust][EVENT_DESC_COL].value_counts().reindex(list(dfc[EVENT_DESC_COL].unique()), fill_value=0))\n",
    "            trace.append(go.Bar(x=x_data, y=y_data, name=cust + \": \" + str(round(len(dfcopy[(dfcopy[CUST_ID_COL] == cust) & (dfcopy[EVENT_DATE_COL] >= start) & (dfcopy[EVENT_DATE_COL] <= end)]) / span, 2)) + \" events per month in given range\"))\n",
    "\n",
    "        # Create the layout\n",
    "        layout = go.Layout(title=f'Event Distribution by Customer, Event: {event_type}', xaxis=dict(title=\"Events\",tickfont = dict(size = 5)), yaxis=dict(title=\"Event Count\"), barmode=\"group\", showlegend = True)\n",
    "\n",
    "        # Create the figure\n",
    "        fig = go.Figure(data=trace, layout=layout)\n",
    "        \n",
    "        file_name = f'events_for_{cust}_by_{event_type}.pdf'\n",
    "\n",
    "        pio.write_image(fig, os.path.join(event_path,file_name), format='pdf')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of customers per event\n",
    "plot_name = 'customer_count_per_event'\n",
    "plot_path = os.path.join(folder_path,plot_name)\n",
    "\n",
    "# Check if the folder already exists before creating it\n",
    "if not os.path.exists(plot_path):\n",
    "    os.mkdir(plot_path)  \n",
    "\n",
    "# UP TO THE USER TO CHOOSE THE DATE RANGES\n",
    "start = df[EVENT_DATE_COL].min()\n",
    "end = df[EVENT_DATE_COL].max()\n",
    "middle = start + (end - start) / 2\n",
    "starts = [start, middle]\n",
    "ends = [middle, end]\n",
    "\n",
    "for event_type in events:\n",
    "    \n",
    "    event_path = os.path.join(plot_path,event_type)\n",
    "\n",
    "    # Check if the folder already exists before creating it\n",
    "    if not os.path.exists(event_path):\n",
    "        os.mkdir(event_path)\n",
    "    \n",
    "    \n",
    "    for i in range(len(starts)):\n",
    "        start = starts[i]\n",
    "        \n",
    "        for j in range(i, len(ends)):\n",
    "            end = ends[j]\n",
    "            \n",
    "            dfc = df.copy()\n",
    "            dfc = dfc[[CUST_ID_COL,EVENT_TYPE_COL,EVENT_DESC_COL,EVENT_DATE_COL]]\n",
    "\n",
    "            if start and end:\n",
    "\n",
    "                dfc = dfc[(dfc[EVENT_DATE_COL] >= start) & (dfc[EVENT_DATE_COL] <= end)]\n",
    "\n",
    "            dfc = dfc[dfc[EVENT_TYPE_COL] == event_type]\n",
    "            \n",
    "\n",
    "            events_to_check = dfc[EVENT_DESC_COL].unique()\n",
    "            trace = []\n",
    "            for event in events_to_check:\n",
    "\n",
    "                dfc2 = dfc[dfc[EVENT_DESC_COL] == event]\n",
    "                # Count the occurrences of each unique customer\n",
    "                customer_counts = dfc2[CUST_ID_COL].value_counts()\n",
    "\n",
    "                # Count the number of customers who appear once, twice, three times, and so on\n",
    "                summary = customer_counts.value_counts().sort_index()\n",
    "\n",
    "                x_data = list(summary.index)\n",
    "                y_data = list(summary)\n",
    "\n",
    "                # Create the bar plot\n",
    "                trace.append(go.Bar(x=x_data, y=y_data, name = event))\n",
    "\n",
    "            # Create the layout\n",
    "            layout = go.Layout(title='Customer Count by event, Event: '+event_type+', Start: '+ start.strftime('%Y-%m-%d') + ', End: '+ end.strftime('%Y-%m-%d'), xaxis=dict(title=\"Number of times event was completed\"), yaxis=dict(title=\"Customer count\"), barmode=\"stack\")\n",
    "\n",
    "            # Create the figure\n",
    "            fig = go.Figure(data=trace, layout=layout)\n",
    "            \n",
    "            fig.update_layout( \n",
    "            title_font=dict(size=10),\n",
    "            legend=dict(font=dict(size=5),\n",
    "                        orientation = 'h',\n",
    "                       y = -1,\n",
    "                       yanchor = 'auto')\n",
    "            )\n",
    "\n",
    "            file_name = event_type+'_from_'+start.strftime('%Y_%m_%d')+'_to_'+end.strftime('%Y_%m_%d')+'.pdf'\n",
    "\n",
    "            pio.write_image(fig, os.path.join(event_path,file_name), format='pdf')\n",
    "            \n",
    "           \n",
    "            # MAKE PLOT WITHOUT BREAKDOWN\n",
    "            customer_counts = dfc[CUST_ID_COL].value_counts()\n",
    "\n",
    "            # Count the number of customers who appear once, twice, three times, and so on\n",
    "            summary = customer_counts.value_counts().sort_index()\n",
    "\n",
    "            x_data = list(summary.index)\n",
    "            y_data = list(summary)\n",
    "            \n",
    "            # Create the bar plot\n",
    "            trace = [go.Bar(x=x_data, y=y_data, name = event)]\n",
    "            \n",
    "            # Create the layout\n",
    "            layout = go.Layout(title='Customer Count by event (no breakdown), Event: '+event_type+', Start: '+ start.strftime('%Y-%m-%d') + ', End: '+ end.strftime('%Y-%m-%d'), xaxis=dict(title=\"Number of times event was completed\"), yaxis=dict(title=\"Customer count\"), barmode=\"stack\")\n",
    "\n",
    "            # Create the figure\n",
    "            fig = go.Figure(data=trace, layout=layout)\n",
    "            \n",
    "            fig.update_layout( \n",
    "            title_font=dict(size=10),  # Set the font size for the title text\n",
    "            )\n",
    "\n",
    "            file_name = event_type+'_from_'+start.strftime('%Y_%m_%d')+'_to_'+end.strftime('%Y_%m_%d')+'_no_breakdown.pdf'\n",
    "\n",
    "            pio.write_image(fig, os.path.join(event_path,file_name), format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter event frequency\n",
    "plot_name = 'numeric_to_frequency'\n",
    "plot_path = os.path.join(folder_path,plot_name)\n",
    "\n",
    "# Check if the folder already exists before creating it\n",
    "if not os.path.exists(plot_path):\n",
    "    os.mkdir(plot_path)\n",
    "    \n",
    "## UP TO THE USER TO CHOOSE DATE RANGES\n",
    "start = df[EVENT_DATE_COL].min()\n",
    "end = df[EVENT_DATE_COL].max()\n",
    "middle = start + (end - start) / 2\n",
    "starts = [start, middle]\n",
    "ends = [middle, end]\n",
    "\n",
    "for event_type in events:\n",
    "    \n",
    "    event_path = os.path.join(plot_path,event_type)\n",
    "\n",
    "    # Check if the folder already exists before creating it\n",
    "    if not os.path.exists(event_path):\n",
    "        os.mkdir(event_path)\n",
    "        \n",
    "    for x_axis in splitting_cols_numeric:\n",
    "    \n",
    "    \n",
    "        for i in range(len(starts)):\n",
    "            start = starts[i]\n",
    "\n",
    "            for j in range(i, len(ends)):\n",
    "                end = ends[j]\n",
    "\n",
    "\n",
    "\n",
    "                dfc = df.copy()\n",
    "\n",
    "                if start and end:\n",
    "                    dfc = dfc[(dfc[EVENT_DATE_COL] >= start) & (dfc[EVENT_DATE_COL] <= end)]\n",
    "\n",
    "                if event_type != 'All events':\n",
    "                    dfc = dfc[dfc[EVENT_TYPE_COL] == event_type]\n",
    "\n",
    "                # Copy the cust_info df to retreive customer ages and account ages\n",
    "                dfcust = df_cust_info\n",
    "                dfcust = dfcust[[CUST_ID_COL,AGE_COL,START_D_COL, SALARY_COL]]\n",
    "                dfcust[AGE_COL] = dfcust[AGE_COL].astype(int)\n",
    "\n",
    "\n",
    "                if x_axis == START_D_COL:\n",
    "\n",
    "                    dfcust = dfcust.sort_values(by=[START_D_COL], ascending = False)\n",
    "                    x_data = pd.Series([(datetime.now() - start_date) for start_date in dfcust[START_D_COL]]).dt.total_seconds() / 86400.0\n",
    "\n",
    "                else:\n",
    "                    dfcust = dfcust.sort_values(by=[x_axis])\n",
    "                    x_data = dfcust[x_axis]\n",
    "\n",
    "                \n",
    "                # ALWAYS WILL BE HISTOGRAM\n",
    "                num_bins = 5\n",
    "                if x_axis == START_D_COL:\n",
    "                    dfcust['bins'] = pd.cut(pd.Series([(datetime.now() - start_date) for start_date in dfcust[START_D_COL]]).dt.total_seconds() / 86400.0 ,bins = num_bins)\n",
    "                else:\n",
    "                    dfcust['bins'] = pd.cut(dfcust[x_axis],bins= num_bins)\n",
    "\n",
    "                merged_df = dfcust.merge(dfc.groupby(CUST_ID_COL).size().reset_index(name='count'), on=CUST_ID_COL, how='left')\n",
    "                span = (end.year - start.year) * 12 + (end.month - start.month) + (float((end.day - start.day)/30))\n",
    "\n",
    "                y_data = merged_df.groupby(by = ['bins'])['count'].mean()\n",
    "                y_data = [num / span for num in y_data]\n",
    "                x_data = sorted(list(dfcust['bins'].astype(str).unique()))\n",
    "                trace = [go.Bar(x = x_data, y = y_data)]\n",
    "\n",
    "                layout = go.Layout(title='Plot of ' + x_axis + ' vs. Event Frequency, Event: '+event_type+', Start: '+ start.strftime('%Y-%m-%d') + ', End: '+ end.strftime('%Y-%m-%d'),\n",
    "                                   xaxis=dict(title=x_axis if x_axis != START_D_COL else x_axis + ' (number of days ago)'),\n",
    "                                   yaxis=dict(title='Event frequency (per month)'),\n",
    "                                   hovermode='closest')\n",
    "                \n",
    "        \n",
    "                fig = go.Figure(data=trace, layout=layout)\n",
    "            \n",
    "                fig.update_layout( \n",
    "                    title_font=dict(size=10),  # Set the font size for the title text\n",
    "                    )\n",
    "\n",
    "\n",
    "                file_name = event_type+'_from_'+start.strftime('%Y_%m_%d')+'_to_'+end.strftime('%Y_%m_%d')+'_by_'+x_axis+'.pdf'\n",
    "\n",
    "                pio.write_image(fig, os.path.join(event_path,file_name), format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
